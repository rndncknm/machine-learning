{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "NBSVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AZKb1wm58TP",
        "colab_type": "text"
      },
      "source": [
        "## NBSVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "Vm87wVK258TQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd, numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "import gc\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDqvoNeP58TV",
        "colab_type": "text"
      },
      "source": [
        "Кроме основного был использован датасет 'Jigsaw train multilingual comments (Google API)'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow-lc-F258TW",
        "colab_type": "code",
        "colab": {},
        "outputId": "45137ced-205f-40ba-bc6e-1bc4f554eeb0"
      },
      "source": [
        "# Loading data\n",
        "\n",
        "train1 = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\")\n",
        "train1['lang'] = 'en'\n",
        "\n",
        "train_es = pd.read_csv('/kaggle/input/jigsaw-train-multilingual-coments-google-api/jigsaw-toxic-comment-train-google-es-cleaned.csv')\n",
        "train_es['lang'] = 'es'\n",
        "\n",
        "train_fr = pd.read_csv('/kaggle/input/jigsaw-train-multilingual-coments-google-api/jigsaw-toxic-comment-train-google-fr-cleaned.csv')\n",
        "train_fr['lang'] = 'fr'\n",
        "\n",
        "train_pt = pd.read_csv('/kaggle/input/jigsaw-train-multilingual-coments-google-api/jigsaw-toxic-comment-train-google-pt-cleaned.csv')\n",
        "train_pt['lang'] = 'pt'\n",
        "\n",
        "train_ru = pd.read_csv('/kaggle/input/jigsaw-train-multilingual-coments-google-api/jigsaw-toxic-comment-train-google-ru-cleaned.csv')\n",
        "train_ru['lang'] = 'ru'\n",
        "\n",
        "train_it = pd.read_csv('/kaggle/input/jigsaw-train-multilingual-coments-google-api/jigsaw-toxic-comment-train-google-it-cleaned.csv')\n",
        "train_it['lang'] = 'it'\n",
        "\n",
        "train_tr = pd.read_csv('/kaggle/input/jigsaw-train-multilingual-coments-google-api/jigsaw-toxic-comment-train-google-tr-cleaned.csv')\n",
        "train_tr['lang'] = 'tr'\n",
        "\n",
        "\n",
        "train = pd.concat([\n",
        "    train1[['comment_text', 'lang', 'toxic']],\n",
        "    train_es[['comment_text', 'lang', 'toxic']],\n",
        "    train_tr[['comment_text', 'lang', 'toxic']],\n",
        "    train_fr[['comment_text', 'lang', 'toxic']],\n",
        "    train_pt[['comment_text', 'lang', 'toxic']],\n",
        "    train_ru[['comment_text', 'lang', 'toxic']],\n",
        "    train_it[['comment_text', 'lang', 'toxic']]  \n",
        "]).sample(n=300000).reset_index(drop=True)\n",
        "\n",
        "del train1, train_es, train_fr, train_pt, train_ru, train_it, train_tr\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sOT-YzF58Tb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv')\n",
        "\n",
        "subm = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JDwESFg58Te",
        "colab_type": "code",
        "colab": {},
        "outputId": "5dfe14b7-48a5-490a-9147-3b2adc86135a"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>lang</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lütfen tahrip etmeyin.</td>\n",
              "      <td>tr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>=== Pakistan Army === \\n I guess your beloved ...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The comment directly above this one are from a...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ogstrokes and 24.239.149.9 are the same person...</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>: Da parte mia, dubito piuttosto che otterrest...</td>\n",
              "      <td>it</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        comment_text lang  toxic\n",
              "0                             Lütfen tahrip etmeyin.   tr      0\n",
              "1  === Pakistan Army === \\n I guess your beloved ...   en      0\n",
              "2  The comment directly above this one are from a...   en      0\n",
              "3  Ogstrokes and 24.239.149.9 are the same person...   en      0\n",
              "4  : Da parte mia, dubito piuttosto che otterrest...   it      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxwnIS8X58Th",
        "colab_type": "text"
      },
      "source": [
        "Пример данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuIMmoi958To",
        "colab_type": "code",
        "colab": {},
        "outputId": "876377ed-ef08-4aeb-9e97-e28fa5d64597"
      },
      "source": [
        "train['comment_text'][2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The comment directly above this one are from a very strange detractor of mine at cplsanchez.infoa fetish fan site authored by a somewhat disturbed individual who has an unrequited attraction to me.  This commentator was banned from this site under several names and is quite consistent about placing the same comment anywhere I write.  The commentator above insists on comparing the standards for entering the military with the FDA standards for donating blood, a ludicrous comparison by someone who has no working knowledge of the military.  I invite the contributors to look at the amateurish Cplsanchez.info, because it shows what the Matt Sanchez should not becomea childish hate site.  \\n\\nI was recently the subject of a Fox News interview:  http://www.foxnews.com/video/index.html?playerId=videolandingpage&streamingFormat;=FLASH&referralObject;=8083220&referralPlaylistId;=7f634ca75753642edb5e38bcd9b77f712d735ea8'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFIXBD7T58Ts",
        "colab_type": "code",
        "colab": {},
        "outputId": "b0525264-547d-4e2e-8eb8-68971abc0568"
      },
      "source": [
        "label_cols = ['toxic']\n",
        "train.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>300000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.096277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.294971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               toxic\n",
              "count  300000.000000\n",
              "mean        0.096277\n",
              "std         0.294971\n",
              "min         0.000000\n",
              "25%         0.000000\n",
              "50%         0.000000\n",
              "75%         0.000000\n",
              "max         1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQA9ZuRD58Tv",
        "colab_type": "text"
      },
      "source": [
        "Заполнение пропусков в трейне и тесте"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmQ_y00t58Tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['comment_text'].fillna(\"unknown\", inplace=True)\n",
        "test['content'].fillna(\"unknown\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLiVOF7h58Ty",
        "colab_type": "text"
      },
      "source": [
        "Обработка комментариев"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ32XzY_58Tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re, string\n",
        "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
        "\n",
        "def tokenize(s): \n",
        "  return re_tok.sub(r' \\1 ', s).split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17IZ5QgU58T2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = train.shape[0]\n",
        "\n",
        "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
        "               strip_accents='unicode', use_idf=1,\n",
        "               smooth_idf=1, sublinear_tf=1 )\n",
        "\n",
        "\n",
        "trn_term_doc = vec.fit_transform(train['comment_text'])\n",
        "test_term_doc = vec.transform(test['content'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL3BiOAg58T-",
        "colab_type": "text"
      },
      "source": [
        "NaiveBayes уравнение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKcJ0qwL58T_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pr(y_i, y):\n",
        "    p = x[y==y_i].sum(0)\n",
        "    return (p+1) / ((y==y_i).sum()+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVaQafjf58UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = trn_term_doc\n",
        "test_x = test_term_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-Mzhfg058UE",
        "colab_type": "text"
      },
      "source": [
        "Модель (здесь были проведены эксперименты с LogisticRegression: разные солверы, количество итераций, параметр dual, также для liblinear была попытка использовать L1-регуляризацию. Лучший результат дала текущая комбинация). В статье написано что L2-регуляризация показывает себя лучше, в LogisticRegression она стоит по дефолту. \n",
        "\n",
        "(https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Cstd84f58UE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mdl(y):\n",
        "    y = y.values\n",
        "    r = np.log(pr(1,y) / pr(0,y))\n",
        "    m = LogisticRegression(C=4, solver='liblinear', dual=True, max_iter=300)\n",
        "    x_nb = x.multiply(r)\n",
        "    return m.fit(x_nb, y), r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW9wh0Iu58UI",
        "colab_type": "text"
      },
      "source": [
        "Предсказание и сабмит"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KghzZxFB58UI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = np.zeros((len(test), len(label_cols)))\n",
        "\n",
        "for i, j in enumerate(label_cols):\n",
        "    m,r = get_mdl(train[j])\n",
        "    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYkZVfis58UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
        "submission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SulKW_Pj681j",
        "colab_type": "text"
      },
      "source": [
        "Public LB : 0.8701"
      ]
    }
  ]
}