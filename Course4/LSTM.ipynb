{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8ooAn-g7a5m",
        "colab_type": "text"
      },
      "source": [
        "## LSTM RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "Happ1Ja17a5n",
        "colab_type": "code",
        "colab": {},
        "outputId": "25d0d6e8-bf91-4ba6-a1e0-6f9001de40f0"
      },
      "source": [
        "import os, warnings, pickle, gc, re, string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "from tensorflow.keras.layers import Layer, Dense, Input, Activation, Embedding, SpatialDropout1D, Bidirectional, LSTM, GRU, GlobalMaxPooling1D, GlobalAveragePooling1D, Dropout\n",
        "from tensorflow.keras.layers import concatenate, add\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4i1UF9m7hDD",
        "colab_type": "text"
      },
      "source": [
        "Гиперпараметры. Также были использованы Crawl и GLoVe эмбеддинги"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "lj3gxF2A7a5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 220\n",
        "MAX_FEATURES = 100000\n",
        "EMBED_SIZE = 600\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "LEARNING_RATE = 8e-4\n",
        "\n",
        "CRAWL_EMB_PATH = '../input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl'\n",
        "GLOVE_EMB_PATH = '../input/pickled-crawl300d2m-for-kernel-competitions/crawl-300d-2M.pkl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NroRU5lb7a5x",
        "colab_type": "text"
      },
      "source": [
        "Вспомогательные функции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGAbI_TA7a5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coeffs(word, *arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "\n",
        "def load_embeddings(embed_dir):\n",
        "    with open(embed_dir, 'rb') as  infile:\n",
        "        embeddings = pickle.load(infile)\n",
        "        return embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJFt3mqP7a51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_embedding_matrix(word_index, embeddings_index, max_features, lower = True, verbose = True):\n",
        "    embedding_matrix = np.zeros((max_features, 300))\n",
        "    for word, i in tqdm(word_index.items(), len=(word_index.items())):\n",
        "        if lower:\n",
        "            word = word.lower()\n",
        "        if i >= max_features: continue\n",
        "        try:\n",
        "            embedding_vector = embeddings_index[word]\n",
        "        except:\n",
        "            embedding_vector = embeddings_index[\"unknown\"]\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6cIWEz67a54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_matrix(word_index, embeddings_index):\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1,300))\n",
        "    for word, i in word_index.items():\n",
        "        try:\n",
        "            embedding_matrix[i] = embeddings_index[word]\n",
        "        except:\n",
        "            embedding_matrix[i] = embeddings_index[\"unknown\"]\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuS4U4gy7a57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(Layer):\n",
        "    def __init__(self, step_dim, W_regularizer=None, b_regularizer=None, \n",
        "                 W_constraint=None, b_constraint=None, bias=True, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = None\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "        self.param_W = {\n",
        "            'initializer': initializers.get('glorot_uniform'),\n",
        "            'name': '{}_W'.format(self.name),\n",
        "            'regularizer': regularizers.get(W_regularizer),\n",
        "            'constraint': constraints.get(W_constraint)\n",
        "        }\n",
        "        self.W = None\n",
        "\n",
        "        self.param_b = {\n",
        "            'initializer': 'zero',\n",
        "            'name': '{}_b'.format(self.name),\n",
        "            'regularizer': regularizers.get(b_regularizer),\n",
        "            'constraint': constraints.get(b_constraint)\n",
        "        }\n",
        "        self.b = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.features_dim = input_shape[-1]\n",
        "        self.W = self.add_weight(shape=(input_shape[-1],), \n",
        "                                 **self.param_W)\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape=(input_shape[1],), \n",
        "                                     **self.param_b)\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        step_dim = self.step_dim\n",
        "        features_dim = self.features_dim\n",
        "\n",
        "        eij = K.reshape(\n",
        "            K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))),\n",
        "            (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "        eij = K.tanh(eij)\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], self.features_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHdV420Z7a5-",
        "colab_type": "text"
      },
      "source": [
        "Получение всех данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlVZkLn87a5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train1 = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\")\n",
        "train2 = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\")\n",
        "\n",
        "train = pd.concat([\n",
        "    train1[['comment_text', 'toxic']],\n",
        "    train2[['comment_text', 'toxic']].query('toxic==1'),\n",
        "    train2[['comment_text', 'toxic']].query('toxic==0').sample(n=100000, random_state=0)\n",
        "])\n",
        "\n",
        "del train1, train2\n",
        "gc.collect()\n",
        "\n",
        "valid = pd.read_csv('/kaggle/input/val-en-df/validation_en.csv')\n",
        "\n",
        "test = pd.read_csv('/kaggle/input/test-en-df/test_en.csv')\n",
        "sub = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKVRgvmu7a6C",
        "colab_type": "text"
      },
      "source": [
        "Обработка текстов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS5n1ULN7a6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "misspell_dict = {\"aren't\": \"are not\", \"can't\": \"cannot\", \"couldn't\": \"could not\",\n",
        "                 \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\",\n",
        "                 \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                 \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\n",
        "                 \"i'd\": \"I had\", \"i'll\": \"I will\", \"i'm\": \"I am\", \"isn't\": \"is not\",\n",
        "                 \"it's\": \"it is\", \"it'll\": \"it will\", \"i've\": \"I have\", \"let's\": \"let us\",\n",
        "                 \"mightn't\": \"might not\", \"mustn't\": \"must not\", \"shan't\": \"shall not\",\n",
        "                 \"she'd\": \"she would\", \"she'll\": \"she will\", \"she's\": \"she is\",\n",
        "                 \"shouldn't\": \"should not\", \"that's\": \"that is\", \"there's\": \"there is\",\n",
        "                 \"they'd\": \"they would\", \"they'll\": \"they will\", \"they're\": \"they are\",\n",
        "                 \"they've\": \"they have\", \"we'd\": \"we would\", \"we're\": \"we are\",\n",
        "                 \"weren't\": \"were not\", \"we've\": \"we have\", \"what'll\": \"what will\",\n",
        "                 \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n",
        "                 \"where's\": \"where is\", \"who'd\": \"who would\", \"who'll\": \"who will\",\n",
        "                 \"who're\": \"who are\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                 \"won't\": \"will not\", \"wouldn't\": \"would not\", \"you'd\": \"you would\",\n",
        "                 \"you'll\": \"you will\", \"you're\": \"you are\", \"you've\": \"you have\",\n",
        "                 \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\": \" will\", \"tryin'\": \"trying\"}\n",
        "\n",
        "\n",
        "def _get_misspell(misspell_dict):\n",
        "    misspell_re = re.compile('(%s)' % '|'.join(misspell_dict.keys()))\n",
        "    return misspell_dict, misspell_re\n",
        "\n",
        "\n",
        "def replace_typical_misspell(text):\n",
        "    misspellings, misspellings_re = _get_misspell(misspell_dict)\n",
        "\n",
        "    def replace(match):\n",
        "        return misspellings[match.group(0)]\n",
        "\n",
        "    return misspellings_re.sub(replace, text)\n",
        "    \n",
        "\n",
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']',\n",
        "          '>', '%', '=', '#', '*', '+', '\\\\', '•', '~', '@', '£', '·', '_', '{', '}', '©', '^',\n",
        "          '®', '`', '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â', '█',\n",
        "          '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶',\n",
        "          '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼',\n",
        "          '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
        "          'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪',\n",
        "          '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\n",
        "\n",
        "\n",
        "def clean_text(x):\n",
        "    x = str(x)\n",
        "    for punct in puncts + list(string.punctuation):\n",
        "        if punct in x:\n",
        "            x = x.replace(punct, f' {punct} ')\n",
        "    return x\n",
        "\n",
        "\n",
        "def clean_numbers(x):\n",
        "    return re.sub(r'\\d+', ' ', x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR0wutko7a6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(train, valid, test, tfms):\n",
        "    for tfm in tfms:\n",
        "        print(tfm.__name__)\n",
        "        train['comment_text'] = train['comment_text'].progress_apply(tfm)\n",
        "        valid['comment_text_en'] = valid['comment_text_en'].progress_apply(tfm)\n",
        "        test['content'] = test['content'].progress_apply(tfm)\n",
        "    \n",
        "    return train, valid, test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w67mSE5h7a6K",
        "colab_type": "code",
        "colab": {
          "referenced_widgets": [
            "fba1b7b005b9474fb945e335d8369e6a",
            "b126d2c23503471b982c36c41a42aa8f",
            "d465e34cd79a4e169975c840f70a4b41",
            "0cbbd9e20e7b458bb727097c8e0b1a54",
            "e74e2c991b924309ab30c17aca745dfc",
            "f776edc8c8db402c8229313c699539ba",
            "cf1c6a07741b486696e74be528158c82",
            "8e71f1f193dd4f58a44340511fef88a2",
            "cbf4e8b8c6ae44d3b7e9605214b10afa"
          ]
        },
        "outputId": "279ff783-e463-401e-9482-bcc53a4bd98b"
      },
      "source": [
        "tfms = [replace_typical_misspell, clean_text, clean_numbers]\n",
        "train, valid, test = preprocess(train, valid, test, tfms)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace_typical_misspell\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fba1b7b005b9474fb945e335d8369e6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=328177.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b126d2c23503471b982c36c41a42aa8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=8000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d465e34cd79a4e169975c840f70a4b41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=63812.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "clean_text\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cbbd9e20e7b458bb727097c8e0b1a54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=328177.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e74e2c991b924309ab30c17aca745dfc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=8000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f776edc8c8db402c8229313c699539ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=63812.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "clean_numbers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf1c6a07741b486696e74be528158c82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=328177.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e71f1f193dd4f58a44340511fef88a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=8000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbf4e8b8c6ae44d3b7e9605214b10afa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=63812.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7toPzjm7a6N",
        "colab_type": "text"
      },
      "source": [
        "Кодирование данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zZ_g_PF7a6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_FEATURES, filters='', lower=False)\n",
        "\n",
        "tokenizer.fit_on_texts(list(train['comment_text']) + list(valid['comment_text_en']) + list(test['content_en']))\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(list(train['comment_text']))\n",
        "y_train = train['toxic'].values\n",
        "\n",
        "X_valid = tokenizer.texts_to_sequences(list(valid['comment_text_en']))\n",
        "y_valid = valid['toxic'].values\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(list(test['content_en']))\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=MAX_LEN)\n",
        "X_valid = pad_sequences(X_valid, maxlen=MAX_LEN)\n",
        "X_test = pad_sequences(X_test, maxlen=MAX_LEN)\n",
        "\n",
        "y_train = train.toxic.values\n",
        "y_valid = valid.toxic.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V_H0Ifl7a6R",
        "colab_type": "text"
      },
      "source": [
        "Матрица эмбеддингов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSofesZI7a6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crawl_embeddings = load_embeddings(CRAWL_EMB_PATH)\n",
        "\n",
        "glove_embeddings = load_embeddings(GLOVE_EMB_PATH)\n",
        "\n",
        "embedding_matrix_1 = build_matrix(word_index, crawl_embeddings)\n",
        "embedding_matrix_2 = build_matrix(word_index, glove_embeddings)\n",
        "\n",
        "embedding_matrix = np.concatenate([embedding_matrix_1, embedding_matrix_2], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwDwPwSQ7a6U",
        "colab_type": "text"
      },
      "source": [
        "Датасеты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvrYP4cZ7a6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((X_train, y_train))\n",
        "    .repeat()\n",
        "    .shuffle(2048)\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "valid_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((X_valid, y_valid))\n",
        "    .batch(BATCH_SIZE)\n",
        "    .cache()\n",
        ")\n",
        "\n",
        "test_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices(X_test)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeYK4E7n7a6X",
        "colab_type": "text"
      },
      "source": [
        "Модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMBL4e857a6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(word_index, embedding_matrix, verbose=True):\n",
        "    sequence_input = Input(shape=(MAX_LEN,), dtype=tf.int32)\n",
        "    \n",
        "    embedding_layer = Embedding(*embedding_matrix.shape,\n",
        "                                weights=[embedding_matrix],\n",
        "                                trainable=False)\n",
        "    \n",
        "    x = embedding_layer(sequence_input)\n",
        "    x = SpatialDropout1D(0.3)(x)\n",
        "    x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    \n",
        "    att = Attention(MAX_LEN)(x)\n",
        "    avg_pool1 = GlobalAveragePooling1D()(x)\n",
        "    max_pool1 = GlobalMaxPooling1D()(x)\n",
        "    hidden = concatenate([att, avg_pool1, max_pool1])\n",
        "    \n",
        "    hidden = Dense(512, activation='relu')(hidden)\n",
        "    hideen = Dense(128, activation='relu')(hidden)\n",
        "\n",
        "    out = Dense(1, activation='sigmoid')(hidden)\n",
        "    \n",
        "    model = Model(sequence_input, out)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZfmnBRk7a6a",
        "colab_type": "code",
        "colab": {},
        "outputId": "af5012d4-fee4-4563-e888-0cfbc2bb36a2"
      },
      "source": [
        "model = build_model(word_index, embedding_matrix)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 220)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 220, 600)     356948400   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d (SpatialDropo (None, 220, 600)     0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 220, 512)     1755136     spatial_dropout1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 220, 256)     656384      bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention (Attention)           (None, 256)          476         bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 256)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 256)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 768)          0           attention[0][0]                  \n",
            "                                                                 global_average_pooling1d[0][0]   \n",
            "                                                                 global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          393728      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            513         dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 359,754,637\n",
            "Trainable params: 2,806,237\n",
            "Non-trainable params: 356,948,400\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywgZYSOm7a6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb = LearningRateScheduler(lambda epoch: LEARNING_RATE * (0.6 ** epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypXry8za7a6f",
        "colab_type": "text"
      },
      "source": [
        "Фит на трейне (английский язык)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNbxbRj87a6f",
        "colab_type": "code",
        "colab": {},
        "outputId": "f50bdd32-3ade-45d2-95c8-7caf1b7e3cac"
      },
      "source": [
        "n_steps = X_train.shape[0] // BATCH_SIZE\n",
        "\n",
        "train_history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=n_steps,\n",
        "    validation_data=valid_dataset,\n",
        "    callbacks=[cb],\n",
        "    epochs=6\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 2563 steps, validate for 63 steps\n",
            "Epoch 1/6\n",
            "2563/2563 [==============================] - 399s 156ms/step - loss: 0.0857 - auc: 0.9797 - val_loss: 0.3241 - val_auc: 0.8933\n",
            "Epoch 2/6\n",
            "2563/2563 [==============================] - 389s 152ms/step - loss: 0.0726 - auc: 0.9855 - val_loss: 0.3451 - val_auc: 0.8843\n",
            "Epoch 3/6\n",
            "2563/2563 [==============================] - 388s 151ms/step - loss: 0.0673 - auc: 0.9878 - val_loss: 0.3900 - val_auc: 0.8612\n",
            "Epoch 4/6\n",
            "2563/2563 [==============================] - 388s 152ms/step - loss: 0.0637 - auc: 0.9890 - val_loss: 0.3852 - val_auc: 0.8724\n",
            "Epoch 5/6\n",
            "2563/2563 [==============================] - 389s 152ms/step - loss: 0.0611 - auc: 0.9901 - val_loss: 0.5394 - val_auc: 0.8249\n",
            "Epoch 6/6\n",
            "2563/2563 [==============================] - 387s 151ms/step - loss: 0.0608 - auc: 0.9901 - val_loss: 0.5679 - val_auc: 0.8116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIF_z5oE7a6i",
        "colab_type": "text"
      },
      "source": [
        "Фит на валидационной выборке (разные языки)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecEKDHtd7a6i",
        "colab_type": "code",
        "colab": {},
        "outputId": "37e89055-bd2a-4bd3-a63e-5fe60f1aa25b"
      },
      "source": [
        "n_steps = X_valid.shape[0] // BATCH_SIZE\n",
        "\n",
        "train_history = model.fit(\n",
        "    valid_dataset.repeat(),\n",
        "    steps_per_epoch=n_steps,\n",
        "    callbacks=[cb],\n",
        "    epochs=4\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 62 steps\n",
            "Epoch 1/4\n",
            "62/62 [==============================] - 12s 194ms/step - loss: 0.2705 - auc: 0.9053\n",
            "Epoch 2/4\n",
            "62/62 [==============================] - 9s 149ms/step - loss: 0.2159 - auc: 0.9348\n",
            "Epoch 3/4\n",
            "62/62 [==============================] - 9s 148ms/step - loss: 0.1993 - auc: 0.9449\n",
            "Epoch 4/4\n",
            "62/62 [==============================] - 9s 148ms/step - loss: 0.1859 - auc: 0.9527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xuAckoR7a6l",
        "colab_type": "code",
        "colab": {},
        "outputId": "7f7bf17c-a830-46ac-896b-bc2c3b03831a"
      },
      "source": [
        "preds = model.predict(test_dataset, verbose=1)\n",
        "sub['toxic'] = preds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "499/499 [==============================] - 35s 69ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wpAnayE7a6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC7m5skx9dUr",
        "colab_type": "text"
      },
      "source": [
        "Public LB : 0.8919"
      ]
    }
  ]
}